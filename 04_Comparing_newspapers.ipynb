{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic comparison of newspapers\n",
    "\n",
    "In this Notebook, we will make some more visualizations of the corpus. Here, we will use the preprocessing that we performed in the previous Notebook, in order to create plots that are a bit less general than the ones we made in Notebook 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "Import the necessary packages for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize\n",
    "with open('data/preprocessed_docs.pkl', 'rb') as f:\n",
    "    processed_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article lengths\n",
    "\n",
    "In the next code block, we will count the number of words in each article and store it in a separate column, called 'article_length'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve the length of each article in the corpus and store it in the DataFrame\n",
    "\n",
    "## Create empty list to store the lengths\n",
    "article_lengths = []\n",
    "\n",
    "## Retrieve length of each article and store in list\n",
    "for index, row in processed_docs.iterrows():\n",
    "    article_lengths.append(len(row['tokens']))\n",
    "\n",
    "## Append list to DataFrame\n",
    "processed_docs['article_length'] = article_lengths\n",
    "\n",
    "## Show the first rows of title, tokens and article length in DataFrame                                    \n",
    "processed_docs[['title', 'tokens', 'article_length']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the distribution of the article length for each paper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of bins\n",
    "num_bins = 10\n",
    "\n",
    "# Calculate bin edges and round to the nearest 100\n",
    "min_length = processed_docs['article_length'].min()\n",
    "max_length = processed_docs['article_length'].max()\n",
    "bin_edges = np.linspace(min_length, max_length, num_bins + 1)\n",
    "bin_edges = np.round(bin_edges, -2)\n",
    "\n",
    "# Creating bins for article length\n",
    "processed_docs['length_bin'] = pd.cut(processed_docs['article_length'], bins=bin_edges, labels=False, include_lowest=True)\n",
    "\n",
    "# Counting the number of articles per bin per paper\n",
    "bin_counts = processed_docs.groupby(['length_bin', 'krantnaam']).size().reset_index(name='counts')\n",
    "\n",
    "# Create the plot\n",
    "fig = px.bar(bin_counts, x='length_bin', y='counts', color='krantnaam', title='Number of articles per length group',\n",
    "             labels={'length_bin': 'Article length (number of words)', 'counts': 'Number of articles'})\n",
    "\n",
    "# Update layout for the x-axis ticks and bar mode\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickmode='array',\n",
    "        tickvals=list(range(len(bin_edges) - 1)),\n",
    "        ticktext=[f'{int(bin_edges[i])}-{int(bin_edges[i+1])}' for i in range(len(bin_edges) - 1)]\n",
    "    ),\n",
    "    barmode='group',  # Change the bar mode to group (bars next to each other)\n",
    "    height=700  # Increase the height of the plot\n",
    ")\n",
    "\n",
    "# Customizing tick labels to be on the same line\n",
    "fig.update_xaxes(tickangle=45)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise outliers with a boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the article lengths for each newspaper\n",
    "newspaper_names = processed_docs['krantnaam'].unique()\n",
    "article_lengths = [processed_docs[processed_docs['krantnaam'] == newspaper]['article_length'] for newspaper in newspaper_names]\n",
    "\n",
    "# Create the box plot\n",
    "fig, ax = plt.subplots(figsize=(5, 6.5))  # width=5 inches, height=6.5 inches\n",
    "\n",
    "# Plot data\n",
    "ax.boxplot(article_lengths, vert=True, patch_artist=True)\n",
    "\n",
    "# Set the title and labels\n",
    "ax.set_title('Article lengths in entire corpus')\n",
    "ax.set_ylabel('Article length (words)')\n",
    "ax.set_xticklabels(newspaper_names, rotation=45, ha='right')  # Set x-axis labels to newspaper names\n",
    "ax.set_xlabel('Newspapers')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at months and days\n",
    "\n",
    "How about differences between different months and days of the week? Does the average article length depend on those factors? Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(processed_docs,\n",
    "                 x='month',\n",
    "                 y='article_length',\n",
    "                 color='krantnaam',\n",
    "                 histfunc='avg')\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Average word count per article per newspaper',\n",
    "    yaxis_title_text='Article length (words)',\n",
    "    xaxis_title_text='Month',\n",
    "    bargap=0.1  # Adjust this value to make the bars narrower (0 to 1)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(processed_docs,\n",
    "                 x='day',\n",
    "                 y='article_length',\n",
    "                 color='krantnaam',\n",
    "                 histfunc='avg')\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Average word count per article per newspaper',\n",
    "    yaxis_title_text='Article length (words)',\n",
    "    xaxis_title_text='Day',\n",
    "    barmode='group',  # Change the bar mode to group (bars next to each other)\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    categoryorder='array',\n",
    "    categoryarray=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'])\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
