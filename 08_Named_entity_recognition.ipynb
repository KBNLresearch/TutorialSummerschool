{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition\n",
    "\n",
    "In this notebook, we will perform named entity recognition on the OCR text.\n",
    "\n",
    "First, we load our preprocessed data into a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Deserialize\n",
    "with open('data/preprocessed_docs.pkl', 'rb') as f:\n",
    "    processed_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the rows without content\n",
    "processed_docs = processed_docs.dropna(subset=['content'])\n",
    "\n",
    "# Show the first rows of the DataFrame\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "processed_docs[['identifier','krantnaam','GPEs']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the entity data in the dataframe\n",
    "\n",
    "With the `displacy` module, we can visualise all kinds of entities in our text.\n",
    "\n",
    "Remember that entities can be extracted from the SpaCy `Doc` objects that are stored in column `doc`.\n",
    "\n",
    "When you like to know the meaning of an entity tag, use the explain function, like this:\n",
    "\n",
    "```python\n",
    "spacy.explain('GPE')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Specify the relative path to the model directory\n",
    "model_path = \"model/nl_core_news_sm\"\n",
    "\n",
    "# Load the model from the relative path\n",
    "nlp = spacy.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "# Get the SpaCy Doc object from the first record in the dataframe\n",
    "doc = processed_docs['doc'].iloc[[1]]\n",
    "\n",
    "# displacy visualises the named entities\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model has made quite some mistakes.\n",
    "\n",
    "Let's continue with GPE data in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot GPE-data to a map\n",
    "\n",
    "The steps:\n",
    "\n",
    "* Load a CSV file with Dutch city coordinates.\n",
    "* Create a mapping of city names to their coordinates.\n",
    "* Look up coordinates for each GPE entity found in our data.\n",
    "* Add a new column with these coordinates to our data.\n",
    "* Plot the coordinates on a map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a CSV file with Dutch city coordinates\n",
    "\n",
    "We wil store the data in a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load coordinates data from CSV\n",
    "coordinates_df = pd.read_csv('data/nl.csv')\n",
    "coordinates_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a mapping of city names to their coordinates\n",
    "\n",
    "We will create a Python dictionary data structure for easy lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Python dictionary mapping city names to coordinates\n",
    "city_to_coords = {row['city']: (row['lat'], row['lng']) for idx, row in coordinates_df.iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look up coordinates for each GPE entity found in our data and add a new column with these coordinates to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get coordinates for GPEs\n",
    "def get_gpe_coords(gpe_list):\n",
    "    return [city_to_coords[gpe] for gpe in gpe_list if gpe in city_to_coords]\n",
    "\n",
    "# Apply the function to create a new column with coordinates\n",
    "processed_docs['GPE_coords'] = processed_docs['GPEs'].apply(get_gpe_coords)\n",
    "\n",
    "# Display the DataFrame\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(processed_docs[['identifier','GPEs','GPE_coords']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see see that no coordinates were found for the places of `http://resolver.kb.nl/resolve?urn=ddd:011065450:mpeg21:a0002:ocr`.\n",
    "This is because the list only contains Dutch place names.\n",
    "\n",
    "The place `Fkankhjjk` does not occur in our lookup list. Neither does `Lemmer`.\n",
    "But `Groningen` and `Amsterdam` do occur in the list.\n",
    "\n",
    "```python\n",
    "city_to_coords['Fkankhjjk']\n",
    "city_to_coords['Groningen']\n",
    "city_to_coords['Lemmer']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_to_coords['Groningen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the coordinates on a map\n",
    "\n",
    "We will use the `folium` library for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Plot the coordinates on a map\n",
    "map = folium.Map(location=[52.0, 5.0], zoom_start=7)\n",
    "\n",
    "for coords_list in processed_docs['GPE_coords']:\n",
    "    for coords in coords_list:\n",
    "        folium.Marker(location=coords).add_to(map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save('map.html')\n",
    "\n",
    "# Display the map\n",
    "map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add different colors for different papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs.krantnaam.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "# Define a color mapping for each unique krantnaam\n",
    "color_mapping = {\n",
    "    'De standaard': 'red',\n",
    "    'Het vaderland : staat- en letterkundig nieuwsblad': 'blue',\n",
    "    'De TÄ³d : godsdienstig-staatkundig dagblad': 'green',\n",
    "}\n",
    "\n",
    "# Plot the coordinates on a map\n",
    "map = folium.Map(location=[52.0, 5.0], zoom_start=7)\n",
    "\n",
    "for index, row in processed_docs.iterrows():\n",
    "    krantnaam = row['krantnaam']\n",
    "    coords_list = row['GPE_coords']\n",
    "    color = color_mapping.get(krantnaam, 'black')  # Default to black if krantnaam not in mapping\n",
    "    \n",
    "    for coords in coords_list:\n",
    "        folium.Marker(location=coords, icon=folium.Icon(color=color)).add_to(map)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map.save('map.html')\n",
    "\n",
    "# Display the map\n",
    "map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add missing cities to the coordinates dictionary\n",
    "\n",
    "To retrieve the coordinates for a city (e.g., Lemmer) from Wikidata using a SPARQL query, you can use the following query:\n",
    "\n",
    "```sparql\n",
    "SELECT ?city ?cityLabel ?coordinates\n",
    "WHERE {\n",
    "  ?city rdfs:label \"Lemmer\"@nl;  # The city name \"Lemmer\"\n",
    "        wdt:P625 ?coordinates.  # The coordinates\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],nl\". }\n",
    "}\n",
    "LIMIT 1\n",
    "```\n",
    "\n",
    "You can run this [SPARQL query](https://w.wiki/AUVP) on the Wikidata Query Service to retrieve the coordinates for Lemmer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPARQL-queries with Python\n",
    "\n",
    "We can use a special Python library for SPARQL queries.\n",
    "\n",
    "This piece of code runs a SPARQL query and returns data in JSON-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import json\n",
    "\n",
    "# Wikidata endpoint\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Define the SPARQL query\n",
    "query = \"\"\"\n",
    "SELECT ?city ?cityLabel ?coordinates\n",
    "WHERE {\n",
    "  ?city rdfs:label \"Lemmer\"@nl; \n",
    "        wdt:P625 ?coordinates.\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],nl\". }\n",
    "}\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    sparql = SPARQLWrapper(endpoint_url)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "result = get_results(endpoint_url, query)\n",
    "\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to retrieve the coordinates from this data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindings = result['results']['bindings'][0]\n",
    "new_city = bindings['cityLabel']['value']\n",
    "new_coordinates = bindings['coordinates']['value']\n",
    "\n",
    "# The coordinates are in the format \"Point(lon lat)\"\n",
    "new_lon, new_lat = new_coordinates.replace('Point(', '').replace(')', '').split()\n",
    "new_coords = (float(new_lat), float(new_lon))\n",
    "\n",
    "# Print the extracted values\n",
    "print(f\"City: {new_city}\")\n",
    "print(f\"Longitude: {new_lon}\")\n",
    "print(f\"Latitude: {new_lat}\")\n",
    "print(f\"Longitude: {new_lon}\")\n",
    "print(f\"new_coords: {new_coords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the new coordinates to the dictionary for lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_to_coords[new_city] = new_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_to_coords['Lemmer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which cells do you have to run again to see Lemmer in te plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix incorrect place names\n",
    "\n",
    "This [article](https://www.delpher.nl/nl/kranten/view?coll=ddd&identifier=ddd:011065450:mpeg21:a0005&objectsearch=Sxeek) shows 'Sxeek' instead of 'Sneek' in the OCR text.\n",
    "\n",
    "Let's replace the places in the dataframe for article `http://resolver.kb.nl/resolve?urn=ddd:011065450:mpeg21:a0005:ocr`\n",
    "\n",
    "Run the code below to replace the placename and update the coordinates. Make sure Sneek exists in the coordinates list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "article_identifier = 'http://resolver.kb.nl/resolve?urn=ddd:011065450:mpeg21:a0005:ocr'\n",
    "old_place = 'Sxeek'\n",
    "new_place = 'Sneek'\n",
    "\n",
    "# Function to extract GPEs from the document\n",
    "def get_gpe(doc):\n",
    "    return [ent.text for ent in doc.ents if ent.label_ == 'GPE']\n",
    "\n",
    "def get_gpe_coords(gpe_list):\n",
    "    return [city_to_coords[gpe] for gpe in gpe_list if gpe in city_to_coords]\n",
    "\n",
    "# Extract the content of the specific row\n",
    "article_text = processed_docs.loc[processed_docs['identifier'] == article_identifier, 'content'].values[0]\n",
    "\n",
    "# Replace the text within that content\n",
    "if old_place in article_text:\n",
    "    # Replace the text within that content\n",
    "    article_text = article_text.replace(old_place, new_place)\n",
    "    \n",
    "    # Update the content column\n",
    "    processed_docs.loc[processed_docs['identifier'] == article_identifier, 'content'] = article_text\n",
    "    \n",
    "    # Update the SpaCy doc column\n",
    "    processed_docs.loc[processed_docs['identifier'] == article_identifier, 'doc'] = processed_docs.loc[processed_docs['identifier'] == article_identifier, 'content'].apply(nlp)\n",
    "\n",
    "    # Update the GPEs column\n",
    "    processed_docs['GPEs'] = processed_docs['doc'].apply(get_gpe)   \n",
    "\n",
    "    # Update the GPE_coords column\n",
    "    processed_docs['GPE_coords'] = processed_docs['GPEs'].apply(get_gpe_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(processed_docs[['identifier', 'GPEs', 'GPE_coords']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
